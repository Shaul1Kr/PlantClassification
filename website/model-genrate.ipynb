{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport matplotlib.pyplot as plt\nimport numpy as np","metadata":{"id":"zBOe-DQenQlO","execution":{"iopub.status.busy":"2022-06-04T17:57:16.546814Z","iopub.execute_input":"2022-06-04T17:57:16.547097Z","iopub.status.idle":"2022-06-04T17:57:16.553883Z","shell.execute_reply.started":"2022-06-04T17:57:16.547066Z","shell.execute_reply":"2022-06-04T17:57:16.552976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rows = 8\ncols = 3\nfig, ax = plt.subplots(rows, cols, figsize=(25,25))\nfig.suptitle(\"Showing one random image from each class\", y=1.05, fontsize=60) # Adding  y=1.05, fontsize=24 helped me fix the suptitle overlapping with axes issue\ndata_dir = \"../input/pytorch-challange-flower-dataset/dataset/train\"\nplant_sorted = sorted(os.listdir(data_dir))\nplant_id = 0\nfor i in range(rows):\n  for j in range(cols):\n    try:\n      plant_selected = plant_sorted[plant_id] \n      plant_id += 1\n    except:\n      break\n    plant_selected_images = os.listdir(os.path.join(data_dir,plant_selected)) # returns the list of all files present in each plant category\n    plant_selected_random = np.random.choice(plant_selected_images) # picks one plant item from the list as choice, takes a list and returns one random item\n    img = plt.imread(os.path.join(data_dir,plant_selected, plant_selected_random))\n    ax[i][j].imshow(img)\n    ax[i][j].set_title(plant_selected, pad = 10 , fontsize=24)\n    \nplt.setp(ax, xticks=[],yticks=[])\nplt.tight_layout()","metadata":{"id":"LZzej3ZUoG_K","execution":{"iopub.status.busy":"2022-06-04T17:57:16.556015Z","iopub.execute_input":"2022-06-04T17:57:16.55629Z","iopub.status.idle":"2022-06-04T17:57:19.910946Z","shell.execute_reply.started":"2022-06-04T17:57:16.556254Z","shell.execute_reply":"2022-06-04T17:57:19.90961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check how many files are in the train folder\ntrain_files = sum([len(files) for i, j, files in os.walk(\"../input/pytorch-challange-flower-dataset/dataset/train\")])\nprint(\"Total number of samples in train folder\")\nprint(train_files)\n\n# Check how many files are in the test folder\ntest_files = sum([len(files) for i, j, files in os.walk(\"../input/pytorch-challange-flower-dataset/dataset/valid\")])\nprint(\"Total number of samples in test folder\")\nprint(test_files)\n\n# Check how many files are in the validation folder\nvalidation_files = sum([len(files) for i, j, files in os.walk(\"../input/pytorch-challange-flower-dataset/dataset/valid\")])\nprint(\"Total number of samples in validation folder\")\nprint(validation_files)","metadata":{"id":"-K_JdeCHoiho","execution":{"iopub.status.busy":"2022-06-04T17:57:19.912392Z","iopub.execute_input":"2022-06-04T17:57:19.912612Z","iopub.status.idle":"2022-06-04T17:57:20.105259Z","shell.execute_reply.started":"2022-06-04T17:57:19.912585Z","shell.execute_reply":"2022-06-04T17:57:20.104459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from __future__ import absolute_import, division, print_function\n\nimport tensorflow as tf\n\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.layers import GlobalAveragePooling2D\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\nfrom tensorflow.keras.optimizers import SGD\nfrom tensorflow.keras.regularizers import l2\n\nfrom tensorflow import keras\nfrom tensorflow.keras import models\nfrom tensorflow.keras.applications.inception_v3 import preprocess_input\n\nimport cv2\nimport os\nimport random\nimport collections\nfrom collections import defaultdict\n\nfrom shutil import copy\nfrom shutil import copytree, rmtree\n\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as img\n\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Input,Dense,Conv2D,Add\nfrom tensorflow.keras.layers import SeparableConv2D,ReLU\nfrom tensorflow.keras.layers import BatchNormalization,MaxPool2D\nfrom tensorflow.keras.layers import GlobalAvgPool2D\nfrom tensorflow.keras import Model\n%matplotlib inline","metadata":{"id":"mSx0MPpKouuv","execution":{"iopub.status.busy":"2022-06-04T18:03:35.027734Z","iopub.execute_input":"2022-06-04T18:03:35.028025Z","iopub.status.idle":"2022-06-04T18:03:35.050087Z","shell.execute_reply.started":"2022-06-04T18:03:35.027995Z","shell.execute_reply":"2022-06-04T18:03:35.049213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model(n_classes,num_epochs, nb_train_samples,nb_validation_samples,iter,type):\n    K.clear_session()\n\n    img_width, img_height = 299, 299\n    if (type == 0):\n        train_data_dir = '../input/dataset-splited/train-20220413T074749Z-001/train'\n        validation_data_dir = '../input/dataset-splited/test-20220413T074851Z-001/test'\n    elif(type == 1):\n        train_data_dir = '../input/pytorch-challange-flower-dataset/dataset/train'\n        validation_data_dir = '../input/pytorch-challange-flower-dataset/dataset/valid'\n    batch_size = 16\n    bestmodel_path = 'bestmodel_'+str(n_classes)+'class.hdf5'\n    trainedmodel_path = 'trainedmodel_'+str(n_classes)+'class.hdf5'\n    #history_path = 'history_'+str(n_classes)+'.log'\n\n    train_datagen = ImageDataGenerator(\n        preprocessing_function=preprocess_input,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True)\n\n    test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n\n    train_generator = train_datagen.flow_from_directory(\n        train_data_dir,\n        target_size=(img_height, img_width),\n        batch_size=batch_size,\n        class_mode='categorical')\n\n    validation_generator = test_datagen.flow_from_directory(\n        validation_data_dir,\n        target_size=(img_height, img_width),\n        batch_size=batch_size,\n        class_mode='categorical')\n\n\n    if(iter == 0):\n        inception = tf.keras.applications.xception.Xception(weights=None,include_top=False)\n    elif(iter == 1):\n        inception = tf.keras.applications.InceptionResNetV2(weights=None, include_top=False)\n    elif(iter == 2):\n        inception = InceptionV3(weights='imagenet', include_top=False)\n    elif(iter == 3):\n        inception = tf.keras.applications.densenet.DenseNet201(weights=None, include_top=False)\n    elif(iter == 4):\n        inception = tf.keras.applications.mobilenet_v2.MobileNetV2( weights=None,include_top=False)\n    elif(iter == 5):\n        inception = tf.keras.applications.vgg19.VGG19(weights=None, include_top=False)\n    elif(iter == 6):\n        inception = tf.keras.applications.vgg16.VGG16(weights=None, include_top=False)\n\n\n\n    x = inception.output\n    x = GlobalAveragePooling2D()(x)\n    x = Dense(128,activation='relu')(x)\n    x = Dropout(0.2)(x)\n\n    predictions = Dense(n_classes,kernel_regularizer=regularizers.l2(0.005), activation='softmax')(x)\n    #callback = tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=20)\n    model = Model(inputs=inception.input, outputs=predictions)\n    model.compile(optimizer=SGD(learning_rate=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n    #checkpoint = ModelCheckpoint(filepath=bestmodel_path, verbose=1, save_best_only=True)\n    #csv_logger = CSVLogger(history_path)\n\n    history = model.fit(train_generator,\n                        steps_per_epoch = nb_train_samples // batch_size,\n                        validation_data=validation_generator,\n                        validation_steps=nb_validation_samples // batch_size,\n                        epochs=num_epochs,\n                        verbose=1)\n\n    #model.save(trainedmodel_path)\n    model.save(\"my_model\")\n    class_map = train_generator.class_indices\n    return history, class_map","metadata":{"id":"2qwflxg0oyVs","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_classes = 23\nepochs = 200\nnb_train_samples = train_files\nnb_validation_samples = test_files\nhistory, class_map_3 = train_model(n_classes,epochs, nb_train_samples,nb_validation_samples,2,0)\nprint(class_map_3)\nprint(history)","metadata":{"id":"7XCxzx7Ao09T","execution":{"iopub.status.busy":"2022-06-04T18:03:46.515742Z","iopub.execute_input":"2022-06-04T18:03:46.516293Z","iopub.status.idle":"2022-06-04T18:07:12.616374Z","shell.execute_reply.started":"2022-06-04T18:03:46.516255Z","shell.execute_reply":"2022-06-04T18:07:12.615568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}